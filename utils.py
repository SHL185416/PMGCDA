import math

import numpy as np
import scipy
import scipy.io as sio
import scipy.sparse as sp
import torch
import torch.nn.functional as F


def load_citation(path):
    r"""load network from citation dataset.

    Load the Citation dataset's network based on the path.

    :arg
        path: the path of the dataset.
    :return
        a: the adjacency matrix of the network.
        x: the feature matrix of the network.
        y: the label matrix of the network.
    """
    net = sio.loadmat(path)
    x, a, y = net['features'], net['adjacency_matrix'], net['labels']
    y = np.eye(y.max() + 1)[y.squeeze(0)]
    if not isinstance(x, scipy.sparse.lil_matrix):
        x = sp.lil_matrix(x)
    return a, x, y


def my_scale_sim_mat_torch(w):
    r"""L1 row norm of a matrix of torch version.

    :arg
        w: a matrix of torch.
    :return
        a: the L1 row norm matrix of w.
    """
    r = 1 / w.sum(1)
    r[r.isinf()] = 0
    return r.diag() @ w


def sim(z1: torch.Tensor, z2: torch.Tensor, hidden_norm: bool = True):
    r"""calculate inner product.

    :arg
        z1: the first matrix.
        z2: the second matrix.
        hidden_norm: whether to normalize the matrix.
    :return
        a: the inner product of z1 and z2.
    """
    if hidden_norm:
        z1 = F.normalize(z1)
        z2 = F.normalize(z2)
    return torch.mm(z1, z2.t())


def calculate_prototype(labels, embs):
    r"""calculate prototype of each class.

    :arg
        labels: node labels
        embs: node embeddings
    :return
        prototypes: prototypes for each category
    """
    norm_Y = my_scale_sim_mat_torch(labels.T)
    prototypes = torch.mm(norm_Y, embs)
    return prototypes


def calculate_prototype_withCount(labels, embs, update_count, prototype_late):
    r"""calculate prototype of each class with update count.

    :arg
        labels: node labels
        embs: node embeddings
        update_count: update count
        prototype_late: late prototype
    :return
        prototypes: prototypes with Count for each category
    """
    prototypes = calculate_prototype(labels, embs)
    for c in range(len(prototypes)):
        if prototypes[c].sum() != 0:
            prototypes[c] = prototypes[c] + update_count[c] * prototype_late[c]
            prototypes[c] = prototypes[c] / (update_count[c] + 1)
            update_count[c] = update_count[c] + 1
        else:
            prototypes[c] = prototype_late[c]
    return prototypes


def calculate_pred_label_t(pred_label_list):
    r"""calculate predicted label.

    Fusion of target network prediction results generated by multiple network specific node classifiers.

    :arg
        pred_label_list: the predicted label list of each network.
    :return
        pred_label: the predicted label.
    """
    pred_label = pred_label_list[0]
    for i in range(1, len(pred_label_list)):
        pred_label = pred_label_list[i] * pred_label
    return pred_label


def one_hot_encode_torch(x, n_classes):
    r""" Convert a class vector (integers) to binary class matrix.

    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.

    :arg
        x: List of sample Labels
    :return
        Numpy array of one-hot encoded labels
     """
    device = x.device
    x = x.type(torch.LongTensor)
    return torch.eye(n_classes)[x].to(device)


def mini_batch(x, y, a, n, batch_size):
    r"""obtain mini-batch

    Randomly select n data points from x and y based on the bias size, and generate the corresponding matrix a.

    :arg
        x: input data
        y: label
        a: adjacency matrix
        n: number of data
    :return
        x: mini-batch data
        y: mini-batch label
        a: mini-batch adjacency matrix
    """
    idx = list(range(x.shape[0]))
    np.random.shuffle(idx)
    n = np.ceil(n / batch_size).astype('int') * batch_size
    idx = (idx * (n // x.shape[0] + bool(n % x.shape[0])))[:n]
    x, y = x[idx], y[idx]
    a = a[idx][:, idx]

    for i in range(n // batch_size + bool(n % batch_size)):
        start, end = i * batch_size, (i + 1) * batch_size
        shuffle_index = idx[i * batch_size:(i + 1) * batch_size]
        yield x[start:end], y[start:end], a[start:end, start:end], shuffle_index


def measures_similarity(p1, p2):
    r"""measures the similarity between two vectors (p1,p2)

    :arg
        p1: vector 1
        p2: vector 2
    :return
        similarity: similarity between p1 and p2
    """
    temp = -(p1 * torch.log(p2) + p2 * torch.log(p1)) / 2
    return temp.sum()


def comb(n, m):
    r"""multiple pairwise combinations

    :arg
        n: the number of elements
        m: the number of elements in each combination
    :return
        the number of combinations
    """
    return math.factorial(n) // (math.factorial(m) * math.factorial(n - m))
